# -*- coding: utf-8 -*-
"""FDM_Mongodb.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/12waSQ-I_FBFsf8Un1JZvLBrAk2qOvr7l
"""

import re
import json  # Import the json module to handle serialization

def sql_to_mongodb(sql_query):
    # Remove extra spaces and standardize spaces
    sql_query = re.sub(r'\s+', ' ', sql_query).strip()

    # Extract SELECT clause
    select_match = re.search(r'select (.+?) from', sql_query, re.IGNORECASE)
    if not select_match:
        raise ValueError("Invalid SQL Query: Missing SELECT clause.")
    select_fields = select_match.group(1).strip()
    select_fields_list = [s.strip() for s in select_fields.split(",")]

    # Extract FROM clause
    from_match = re.search(r'from (\S+)', sql_query, re.IGNORECASE)
    if not from_match:
        raise ValueError("Invalid SQL Query: Missing FROM clause.")
    collection_name = from_match.group(1).strip()

    # Extract WHERE clause
    where_match = re.search(r'where (.+?)( group by| order by| having| limit|$)', sql_query, re.IGNORECASE)
    where_clause = where_match.group(1).strip() if where_match else None

    # Extract GROUP BY clause
    group_by_match = re.search(r'group by (.+?)( having| order by| limit|$)', sql_query, re.IGNORECASE)
    group_by_fields = [field.strip() for field in group_by_match.group(1).split(',')] if group_by_match else None

    # Extract HAVING clause
    having_match = re.search(r'having (.+?)( order by| limit|$)', sql_query, re.IGNORECASE)
    having_clause = having_match.group(1).strip() if having_match else None

    # Extract ORDER BY clause
    order_by_match = re.search(r'order by (.+?)( limit|$)', sql_query, re.IGNORECASE)
    order_by_clause = order_by_match.group(1).strip() if order_by_match else None

    # Extract LIMIT clause
    limit_match = re.search(r'limit (\d+)', sql_query, re.IGNORECASE)
    limit_value = int(limit_match.group(1).strip()) if limit_match else None

    # Initialize the MongoDB aggregation pipeline
    pipeline = []

    # WHERE clause processing
    if where_clause:
        match_conditions = {}
        for condition in re.split(r'\s+and\s+', where_clause, flags=re.IGNORECASE):
            parts = re.split(r'\s*(=|>|<|>=|<=|!=)\s*', condition)
            if len(parts) < 3:
                continue  # Skip invalid conditions
            field, operator, value = parts[0], parts[1], parts[2]
            field = field.strip()
            value = value.strip().strip("'")

            # Attempt to convert value to float if possible
            try:
                value = float(value)
            except ValueError:
                pass  # Keep as string if not a number

            # Build the match condition based on the operator
            if operator == "=":
                match_conditions[field] = value
            elif operator == "!=":
                match_conditions[field] = {"$ne": value}
            else:
                mongo_operator = {"<": "$lt", "<=": "$lte", ">": "$gt", ">=": "$gte"}[operator]
                match_conditions[field] = {mongo_operator: value}

        pipeline.append({"$match": match_conditions})

    # GROUP BY and Aggregation processing
    agg_fields = {}  # Map for HAVING and projection
    group_needed = group_by_fields or any(re.search(r'(sum|avg|count|max|min)\(', field, re.IGNORECASE) for field in select_fields_list)
    if group_needed:
        group_stage = {"$group": {"_id": {}}}
        if group_by_fields:
            for field in group_by_fields:
                group_stage["$group"]["_id"][field] = f"${field}"
        else:
            group_stage["$group"]["_id"] = None  # Aggregation without grouping fields

        # Process aggregation functions in SELECT clause
        for select_field in select_fields_list:
            agg_match = re.match(r'(sum|avg|count|max|min)\((.*?)\)(?:\s+as\s+(\w+))?', select_field, re.IGNORECASE)
            if agg_match:
                func = agg_match.group(1).lower()
                agg_field = agg_match.group(2).strip()
                alias = agg_match.group(3) or f"{func}_{agg_field}"
                original_expr = f"{func}({agg_field})"
                if func == 'count':
                    if agg_field == '*':
                        group_stage["$group"][alias] = {'$sum': 1}
                    else:
                        # Correctly handle COUNT(field) by summing 1 when field is not null
                        group_stage["$group"][alias] = {
                            '$sum': {
                                '$cond': [{'$ne': [f"${agg_field}", None]}, 1, 0]
                            }
                        }
                else:
                    group_stage["$group"][alias] = {f"${func}": f"${agg_field}"}
                # Map the normalized original expression to alias
                agg_fields[re.sub(r'\s+', '', original_expr.lower())] = alias
            else:
                # Non-aggregated fields
                field_alias_match = re.match(r'(\w+)\s+as\s+(\w+)', select_field, re.IGNORECASE)
                if field_alias_match:
                    field_name = field_alias_match.group(1)
                    alias = field_alias_match.group(2)
                    if group_by_fields:
                        group_stage["$group"]["_id"][alias] = f"${field_name}"
                elif group_by_fields and select_field.strip() in group_by_fields:
                    # Field is already in group_by_fields
                    pass
                else:
                    # If not grouped, can't include non-aggregated fields
                    if not group_by_fields:
                        raise ValueError(f"Cannot include field '{select_field.strip()}' without grouping.")
        pipeline.append(group_stage)

    # HAVING clause processing
    if having_clause:
        having_conditions = {}
        for condition in re.split(r'\s+and\s+', having_clause, flags=re.IGNORECASE):
            parts = re.split(r'\s*(=|>|<|>=|<=|!=)\s*', condition)
            if len(parts) < 3:
                continue  # Skip invalid conditions
            field_expr, operator, value = parts[0], parts[1], parts[2]
            field_expr = field_expr.strip()
            value = value.strip()
            # Attempt to convert value to float if possible
            try:
                value = float(value)
            except ValueError:
                pass  # Keep as string if not a number

            # Map the field expression to the aggregation alias
            normalized_field_expr = re.sub(r'\s+', '', field_expr.lower())
            field_name = agg_fields.get(normalized_field_expr, field_expr)

            # Build the match condition based on the operator
            if operator == "=":
                having_conditions[field_name] = value
            elif operator == "!=":
                having_conditions[field_name] = {"$ne": value}
            else:
                mongo_operator = {"<": "$lt", "<=": "$lte", ">": "$gt", ">=": "$gte"}[operator]
                having_conditions[field_name] = {mongo_operator: value}

        pipeline.append({"$match": having_conditions})

    # ORDER BY clause processing
    if order_by_clause:
        sort_conditions = {}
        for field_order in order_by_clause.split(","):
            parts = field_order.strip().split()
            field = parts[0]
            order = parts[1].lower() if len(parts) > 1 else "asc"
            sort_order = 1 if order == "asc" else -1
            sort_conditions[field] = sort_order
        pipeline.append({"$sort": sort_conditions})

    # LIMIT clause processing
    if limit_value:
        pipeline.append({"$limit": limit_value})

    # SELECT clause processing (Projection)
    if select_fields != "*":
        project_fields = {}
        for field in select_fields_list:
            agg_match = re.match(r'(sum|avg|count|max|min)\((.*?)\)(?:\s+as\s+(\w+))?', field, re.IGNORECASE)
            if agg_match:
                # Aggregated fields
                func = agg_match.group(1).lower()
                agg_field = agg_match.group(2).strip()
                alias = agg_match.group(3) or f"{func}_{agg_field}"
                project_fields[alias] = f"${alias}"
            else:
                # Non-aggregated fields
                field_alias_match = re.match(r'(\w+)\s+as\s+(\w+)', field, re.IGNORECASE)
                if field_alias_match:
                    field_name = field_alias_match.group(1)
                    alias = field_alias_match.group(2)
                else:
                    field_name = field
                    alias = field

                if group_needed:
                    # Fields from the _id in group stage
                    project_fields[alias] = f"$_id.{field_name}"
                else:
                    # Direct fields from documents
                    project_fields[alias] = 1

        # Exclude the _id field if not needed
        if not group_needed:
            project_fields["_id"] = 0
        pipeline.append({"$project": project_fields})

    # **Modification Starts Here**
    # Serialize the pipeline to JSON to replace Python's None with JavaScript's null
    pipeline_str = json.dumps(pipeline)
    # **Modification Ends Here**

    # Return the final MongoDB query string
    print("in function",f"db.{collection_name}.aggregate({pipeline_str})")
    return f"db.{collection_name}.aggregate({pipeline_str})"


# import re

# def sql_to_mongodb(sql_query):
#     # Remove extra spaces and standardize spaces
#     sql_query = re.sub(r'\s+', ' ', sql_query).strip()

#     # Extract SELECT clause
#     select_match = re.search(r'select (.+?) from', sql_query, re.IGNORECASE)
#     if not select_match:
#         raise ValueError("Invalid SQL Query: Missing SELECT clause.")
#     select_fields = select_match.group(1).strip()
#     select_fields_list = [s.strip() for s in select_fields.split(",")]

#     # Extract FROM clause
#     from_match = re.search(r'from (\S+)', sql_query, re.IGNORECASE)
#     if not from_match:
#         raise ValueError("Invalid SQL Query: Missing FROM clause.")
#     collection_name = from_match.group(1).strip()

#     # Extract WHERE clause
#     where_match = re.search(r'where (.+?)( group by| order by| having| limit|$)', sql_query, re.IGNORECASE)
#     where_clause = where_match.group(1).strip() if where_match else None

#     # Extract GROUP BY clause
#     group_by_match = re.search(r'group by (.+?)( having| order by| limit|$)', sql_query, re.IGNORECASE)
#     group_by_fields = [field.strip() for field in group_by_match.group(1).split(',')] if group_by_match else None

#     # Extract HAVING clause
#     having_match = re.search(r'having (.+?)( order by| limit|$)', sql_query, re.IGNORECASE)
#     having_clause = having_match.group(1).strip() if having_match else None

#     # Extract ORDER BY clause
#     order_by_match = re.search(r'order by (.+?)( limit|$)', sql_query, re.IGNORECASE)
#     order_by_clause = order_by_match.group(1).strip() if order_by_match else None

#     # Extract LIMIT clause
#     limit_match = re.search(r'limit (\d+)', sql_query, re.IGNORECASE)
#     limit_value = int(limit_match.group(1).strip()) if limit_match else None

#     # Initialize the MongoDB aggregation pipeline
#     pipeline = []

#     # WHERE clause processing
#     if where_clause:
#         match_conditions = {}
#         for condition in re.split(r'\s+and\s+', where_clause, flags=re.IGNORECASE):
#             parts = re.split(r'\s*(=|>|<|>=|<=|!=)\s*', condition)
#             if len(parts) < 3:
#                 continue  # Skip invalid conditions
#             field, operator, value = parts[0], parts[1], parts[2]
#             field = field.strip()
#             value = value.strip().strip("'")

#             # Attempt to convert value to float if possible
#             try:
#                 value = float(value)
#             except ValueError:
#                 pass  # Keep as string if not a number

#             # Build the match condition based on the operator
#             if operator == "=":
#                 match_conditions[field] = value
#             elif operator == "!=":
#                 match_conditions[field] = {"$ne": value}
#             else:
#                 mongo_operator = {"<": "$lt", "<=": "$lte", ">": "$gt", ">=": "$gte"}[operator]
#                 match_conditions[field] = {mongo_operator: value}

#         pipeline.append({"$match": match_conditions})

#     # GROUP BY and Aggregation processing
#     agg_fields = {}  # Map for HAVING and projection
#     group_needed = group_by_fields or any(re.search(r'(sum|avg|count|max|min)\(', field, re.IGNORECASE) for field in select_fields_list)
#     if group_needed:
#         group_stage = {"$group": {"_id": {}}}
#         if group_by_fields:
#             for field in group_by_fields:
#                 group_stage["$group"]["_id"][field] = f"${field}"
#         else:
#             group_stage["$group"]["_id"] = None  # Aggregation without grouping fields

#         # Process aggregation functions in SELECT clause
#         for select_field in select_fields_list:
#             agg_match = re.match(r'(sum|avg|count|max|min)\((.*?)\)(?:\s+as\s+(\w+))?', select_field, re.IGNORECASE)
#             if agg_match:
#                 func = agg_match.group(1).lower()
#                 agg_field = agg_match.group(2).strip()
#                 alias = agg_match.group(3) or f"{func}_{agg_field}"
#                 original_expr = f"{func}({agg_field})"
#                 if func == 'count' and agg_field == '*':
#                     group_stage["$group"][alias] = {'$sum': 1}
#                 else:
#                     group_stage["$group"][alias] = {f"${func}": f"${agg_field}"}
#                 # Map the normalized original expression to alias
#                 agg_fields[re.sub(r'\s+', '', original_expr.lower())] = alias
#             else:
#                 # Non-aggregated fields
#                 field_alias_match = re.match(r'(\w+)\s+as\s+(\w+)', select_field, re.IGNORECASE)
#                 if field_alias_match:
#                     field_name = field_alias_match.group(1)
#                     alias = field_alias_match.group(2)
#                     if group_by_fields:
#                         group_stage["$group"]["_id"][alias] = f"${field_name}"
#                 elif group_by_fields and select_field.strip() in group_by_fields:
#                     # Field is already in group_by_fields
#                     pass
#                 else:
#                     # If not grouped, can't include non-aggregated fields
#                     if not group_by_fields:
#                         raise ValueError(f"Cannot include field '{select_field.strip()}' without grouping.")
#         pipeline.append(group_stage)

#     # HAVING clause processing
#     if having_clause:
#         having_conditions = {}
#         for condition in re.split(r'\s+and\s+', having_clause, flags=re.IGNORECASE):
#             parts = re.split(r'\s*(=|>|<|>=|<=|!=)\s*', condition)
#             if len(parts) < 3:
#                 continue  # Skip invalid conditions
#             field_expr, operator, value = parts[0], parts[1], parts[2]
#             field_expr = field_expr.strip()
#             value = value.strip()
#             # Attempt to convert value to float if possible
#             try:
#                 value = float(value)
#             except ValueError:
#                 pass  # Keep as string if not a number

#             # Map the field expression to the aggregation alias
#             normalized_field_expr = re.sub(r'\s+', '', field_expr.lower())
#             field_name = agg_fields.get(normalized_field_expr, field_expr)

#             # Build the match condition based on the operator
#             if operator == "=":
#                 having_conditions[field_name] = value
#             elif operator == "!=":
#                 having_conditions[field_name] = {"$ne": value}
#             else:
#                 mongo_operator = {"<": "$lt", "<=": "$lte", ">": "$gt", ">=": "$gte"}[operator]
#                 having_conditions[field_name] = {mongo_operator: value}

#         pipeline.append({"$match": having_conditions})

#     # ORDER BY clause processing
#     if order_by_clause:
#         sort_conditions = {}
#         for field_order in order_by_clause.split(","):
#             parts = field_order.strip().split()
#             field = parts[0]
#             order = parts[1].lower() if len(parts) > 1 else "asc"
#             sort_order = 1 if order == "asc" else -1
#             sort_conditions[field] = sort_order
#         pipeline.append({"$sort": sort_conditions})

#     # LIMIT clause processing
#     if limit_value:
#         pipeline.append({"$limit": limit_value})

#     # SELECT clause processing (Projection)
#     if select_fields != "*":
#         project_fields = {}
#         for field in select_fields_list:
#             agg_match = re.match(r'(sum|avg|count|max|min)\((.*?)\)(?:\s+as\s+(\w+))?', field, re.IGNORECASE)
#             if agg_match:
#                 # Aggregated fields
#                 func = agg_match.group(1).lower()
#                 agg_field = agg_match.group(2).strip()
#                 alias = agg_match.group(3) or f"{func}_{agg_field}"
#                 project_fields[alias] = f"${alias}"
#             else:
#                 # Non-aggregated fields
#                 field_alias_match = re.match(r'(\w+)\s+as\s+(\w+)', field, re.IGNORECASE)
#                 if field_alias_match:
#                     field_name = field_alias_match.group(1)
#                     alias = field_alias_match.group(2)
#                 else:
#                     field_name = field
#                     alias = field

#                 if group_needed:
#                     # Fields from the _id in group stage
#                     project_fields[alias] = f"$_id.{field_name}"
#                 else:
#                     # Direct fields from documents
#                     project_fields[alias] = 1

#         # Exclude the _id field if not needed
#         if not group_needed:
#             project_fields["_id"] = 0
#         pipeline.append({"$project": project_fields})

#     # Return the final MongoDB query string
#     return f"db.{collection_name}.aggregate({pipeline})"